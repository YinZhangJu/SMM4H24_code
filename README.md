# SMM4H24

This repo holds codes of the papers: Cross-lingual Few-shot Medical Entity Extraction using a Large Language Model

## Prerequisites
- To manage Python environments and packages, you will need to download Anaconda.

- This project is implemented in Pytorch. Thus please install Pytorch first.

-  Please install the Python SDK from the following link: https://github.com/zhipuai/zhipuai-sdk-python-v4. This will allow you to make API calls to the model.

## Data Preparation
If you need the dataset, please contact the organizers of SMM4H-2024 Task 2. The contact information is smm4h-2024-task-2@googlegroups.com.

## Usage
### data_loader
This portion of the code reads the filenames of all ".txt" files in the dataset and saves them in a CSV file named "dataname."

Please replace the following address with the location of the local dataset.
```python
data_path = './SMM4H_2024_Task_2_test'
```
Set "dataname" to the local path where you want to save.
```python
dataname.to_csv("./test_result_data/dataname.csv")
```

### glm_train_optimize
This portion of the code calls the GLM API. Then, it inputs the dataset through our prompts into the model. When encountering a sample containing sensitive content, the model stops running. When our system detect such stops, it records and collects the id of the corresponding input sample, then skip the sample and continue generation for the next sample. After the first run, we manually checked the recored samples, identify and remove the sensitive words in the sample. Then we resume the generation for these preprocessed samples. Finally, all the generated results are written into a CSV file, which undergoes further processing for better visualization.

You need to fill in your own GLM API in this section.
```python
client = ZhipuAI(
    api_key=" "
)  # 填写您自己的APIKey
```
Please replace the following address with the location of the local dataset.
```python
Data_con("./SMM4H_2024_Task_2_test", inputresult)
```
Replace all the paths of "result" below with the desired local path where you want to save the data.
```python
outputresult.to_csv("./test_result_data/result.csv")
df = pd.read_csv("./test_result_data/result.csv")
df.columns = ["no", "content", "ADE"]
df = df[df.iloc[:, 0] != 1]
df = df[df.iloc[:, 0] != 2]
df = df.drop("no", axis="columns")
df = df.drop("content", axis="columns")
df.to_csv("./test_result_data/result.csv", index=False, encoding="utf-8")
```
Please modify the following paths to the desired locations where you want to save the data.
```python
pd.DataFrame(error_records).to_csv(
    "log/error_records.csv", index=False, encoding="utf-8"
)
```

### brat_data
This code transforms the results generated by the model into the brat format required for competition submission.

Please replace the following addresses with the local paths where "dataname" and "result" are located.
```python
output_path = './test_result_data/result.csv'
title_path = './test_result_data/dataname.csv'
```
Please replace the addresses within the quotation marks below with the location of the dataset
```python
with open('test_result_data/result/' + title + '.txt', 'r', encoding='utf-8') as file3:
```
